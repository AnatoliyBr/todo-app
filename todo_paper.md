# Мой опыт создания REST API сервера для ведения todo-списков

![todo_paper](/assets/images/todo_paper_cover.png 'todo_paper')

## Содержание
* [Подготовка репозитория](#подготовка-репозитория)
* [Конфигурирование приложения](#конфигурирование-приложения)
* [Создание базы данных в PostgreSQL](#создание-базы-данных-в-postgresql)
* [Подключение к базе данных из Go](#подключение-к-базе-данных-из-go)
* [Миграции базы данных](#миграции-базы-данных)
* [Бизнес-сущности (слой Entity)](#бизнес-сущности-слой-entity)
* [Интерфейсы хранилища и репозиториев](#интерфейсы-хранилища-и-репозиториев)
* [Реализация интерфейса хранилища (слой Store)](#реализация-интерфейса-хранилища-слой-store)
* [Реализации интерфейсов репозиториев](#реализации-интерфейсов-репозиториев)
* [Реализация sqlrepository](#реализация-sqlrepository)
* [Тестирование репозиториев в пакете sqlrepository](#тестирование-репозиториев-в-пакете-sqlrepository)
* [Валидация модели пользователя и хэширование пароля](#валидация-модели-пользователя-и-хэширование-пароля)
* [Реализация и тестирование testrepository](#реализация-и-тестирование-testrepository)
* [Бизнес-логика (слой UseCase)](#бизнес-логика-слой-usecase)
* [Структура REST API](#структура-rest-api)
* [Endpoint для регистрации пользователя](#endpoint-для-регистрации-пользователя)
* [Принцип Stateless](#принцип-stateless)
* [Стандарт JSON Web Token (JWT)](#стандарт-json-web-token-jwt)
* [Endpoint для аутентификации пользователя и выдачи JWT](#endpoint-для-аутентификации-пользователя-и-выдачи-jwt)
* [Middleware-компоненты. Пакет context](#middleware-компоненты-пакет-context)
* [Middleware-компонент для проверки аутентификации пользователя по JWT](#middleware-компонент-для-проверки-аутентификации-пользователя-по-jwt)
* [Middleware-компонент для CORS](#middleware-компонент-для-cors)
* [Middleware-компонент для RequestID](#middleware-компонент-для-requestid)
* [Middleware-компонент для логирования](#middleware-компонент-для-логирования)
* [Контейнеризация приложения. Dockerfile](#контейнеризация-приложения-dockerfile)
* [Развертывание приложения. Docker Compose](#развертывание-приложения-docker-compose)
* [Полезные ссылки](#полезные-ссылки)

## Подготовка репозитория
Создал директорию проекта.

На Windows (Command Prompt) команды следующие:

```bash
E:
cd E:\HDD\Magistracy\EducationCourses\ITMO\
mkdir todo-app
cd .\todo-app
```

Создал файлы `README.md` и `LICENSE`.

В `README.md` записал структуру проекта.

Также добавил **схему базы данных**, которую создал в [dbdesigner](https://app.dbdesigner.net) и сохранил в директорию `/assets/images`.

Создал `.gitignore` для игнорирования исполняемого файла приложения `app.exe` и файла с переменными окружения `.env` (`/` обозначает, что будут исключены только файлы, находящиеся в корневой директории проекта).

```
/app.exe
/.env
```

Инициализировал репозиторий, сделал `initial commit` и опубликовал его через IDE:

```bash
git init
git add -A
git commit -m "initial commit"
```

## Конфигурирование приложения
Инициализировал go модуль, чтобы можно было отследить зависимости (библиотеки, используемые в проекте).

```bash
go mod init github.com/AnatoliyBr/todo-app
```

Создал точку входа в приложение - директорию `cmd/app` с файлом `main.go`. Здесь вызывается функция `Run()`.

Создал директорию `internal/app` с файлом `app.go` и определил функцию `Run()`, в которой вызываются конструкторы.

Создал директорию `internal/controller/apiserver` с файлом `apiserver.go`, в котором определил структуру сервера с конструктором (`NewServer`) и методами (`configureRouter`, `StartServer`, `ServeHTTP` (полезен при тестировании)). В той же директории создал файл `config.go`, в котором определил структуру конфига с конструктором (`NewConfig`).

Структура сервера содежит поле роутера (сущность, которая отвечает на http-запросы), в качестве нее использовал роутер из библиотеки **gorilla/mux**, который импортировал командой `go get`.

```bash
go get github.com/gorilla/mux
```

Чтобы не запоминать команды, которые использовались во время разработки и тестирования, фиксировал их в `Makefile`.

<details>
<summary> Работа с Makefile на Windows</summary>

На Windows для работы с `Makefile` пришлось скачать linux-подобное окружение [MinGw](https://sourceforge.net/projects/mingw-w64/). Далее надо было скопировать `mingw32-make.exe`, переименовать утилиту на `make.exe` и указать путь до нее в переменной окружения `Path`.
</details>

Создал в `Makefile` **цель/задачу (target/task)** `build` для сборки приложения. Помним, что цели, не соответствующие файлам, и предназначенные для выполнения набора команд или группировки завимостей, декларируются с помощью `.PHONY`:

```Makefile
.PHONY: build
build:
			go build -v ./cmd/app
```

Также установил эту цель в качестве стандартной задачи по умолчанию:

```Makefile
.DEFAULT_GOAL := build
```

Замечу, что при использовании пробелов вместо табуляции в `Makefile` возникнет ошибка.

Создал директорию `configs` с файлом `apiserver.toml` с помощью которого будет конфигурироваться наше приложение.

Для работы с `.toml` файлами установил библиотеку **BurntSushi/toml**:

```
go get github.com/BurntSushi/toml
```

Чтобы передать путь к конфигурационному файлу с флагом `-config-path` при запуске исполняемого файла приложения `app.exe`, использовал библиотеку `flag`.

А именно, в каталоге `internal/app` определил глобальную переменную `configPath` и функцию `init` перед функцией `Run`. Помним, что в Go функция `init` выполняется автоматически при инициализации пакета и используется для инициализации глобальных переменных.

Чтобы привязать флаг к переменной, вызвал функцию `flag.StringVar` в `init`. Чтобы распарсить флаг, вызывал функцию `flag.Parse` в `Run`, а также функцию `toml.DecodeFile`, чтобы считать параметры из конфигурационного файла.

При запуске исполняемого файла с флагом `-help` выводится информация о доступных флагах.

Написал обработчик `handleHello` для тестового маршрута (route) `/hello`:

```go
func (s *server) handleHello() http.HandlerFunc {
    // some variables

    return func(w http.ResponseWriter, r *http.Request) {
        io.WriteString(w, "hello")
    }
}
```

Замечу, что в качестве обработчика удобно использовать не привычную функцию с сигнатурой (`func(w http.ResponseWriter, r *http.Request)`), а функцию, возвращающую функцию типа `http.HandlerFunc`.

Идея в том, что перед `return` можно определить локальные специфичные типы, которые будут использоваться только в этом обработчике, например, структуру, описывающую формат запроса.

Таким образом, код не захламляется, локальные типы хранятся перед глазами, а вся логика обработки каждого запроса описывается внутри функции, которую возвращаем.

Оправил запрос с помощью утилиты `curl`:

```bash
curl "http://localhost:8080/hello"
```

Создал файл `apiserver_internal_test.go`, суффикс `internal`, так как тестировал приватные методы.

Для модульного тестирования использовал библиотеку **stretchr/testify**, которая предлагает множество удобных методов, которые упрощают написание утверждений (**assert**), например `assert.Equal`.

```bash
go get github.com/stretchr/testify
```

Замечу, что в данном случае не тестируется веб-сервер, как отдельный процесс на отдельном порту, а тестируется лишь функция обработчик.

При этом ей передается объект, который удовлетворяет интерфейсу `http.ResponseWriter` из библиотеки **httptest** - `Recorder`, который создается функцией `httptest.NewRecorder`. В него можно записать ответ и прочесть его в тестах.

Чтобы создать http-запрос, использовал функцию `http.NewRequest`.

Чтобы вызвать функцию обработчик, использовал метод `ServeHTTP(rec, req)`.

Добавил в `Makefile` задачу `test` с флагами `-v` (подробный вывод, протоколирующий все тесты по мере их запуска) и `-race` (детектор состояния гонки):

```Makefile
.PHONY: test
test:
			go test -v -race ./...
```

Можно также добавить флаг `-timeout 30s`, который запускает `panic`, если тестовый бинарный файл работает дольше, чем продолжительность `d` (в частности 30 секунд).

Для обновления файла `go.mod` использовал команду:

```bash
go mod tidy
```

## Создание базы данных в PostgreSQL
Перед определением бизнес-сущностей (entity: `User`, `List`, `Task`) и сущности хранилища (`Store`) провел подготовительную работу по установке СУБД **PostgreSQL**.

Замечу также, что можно было запустить PostgreSQL в **Docker** контейнере.

<details>
    <summary> Работа с PostgreSQL на Windows</summary>

На Windows для работы с PostgreSQL пришлось скачать установщик [Windows installers](https://www.postgresql.org/download/windows/) с официального сайта. Установщик включал PostgreSQL **сервер** и **консольную утилиту** `psql` (точнее файл `runpsql.bat`, который можно скопировать, переименовать и указать путь до него в переменной окружения `Path`, как и в случае с `mingw32-make` утилитой).

Во время установки необходимо выбрать параметр языка (`locale`) равным `C`, иначе сообщения от СУБД будут отображаться не корректно.

Кроме того, во время установки можно выбрать директорию хранения баз данных (`data_directory`). В утилите `psql` текущую директорию можно посмотреть командой `show data_directory;`.

Поменять эту директорию после установки утилиты можно с помощью [следующих команд](https://stackoverflow.com/questions/22596301/how-to-change-postgresql-data-directory).

<details>
    <summary> Команды</summary>

1. Останавливаем службу:

```bash
sc stop postgresql-x64-11
```

2. Меняем директорию у флага `-D`:

```bash
sc config postgresql-x64-11 binPath= "\"C:\Program Files\PostgreSQL\11\bin\pg_ctl.exe\" runservice -N \"postgresql-x64-11\" -D \"E:\HDD\Magistracy\postgre\data" -w"
```

3. Запускаем службу:

```bash
sc start postgresql-x64-11
```

4. Посмотреть статус службы можно с помощью команды:

```bash
sc queryex postgresql-x64-11
```
</details>

</details>

Для корректного отображения информации в командной строке при работе с утилитой `psql`, поменял **кодировку** страницы командой:

```bash
chcp 1251
```

<details>
    <summary> chcp</summary>

* `chcp` - вывести текущую кодировку страницы (по умолчанию **CP866**)
* `chcp 1251` - сменить кодировку страницы на **Windows 1251**
</details>

<details>
    <summary> Команды psql и SQL</summary>

`psql` - интерфейс командной строки к **PostgreSQL**.

* `\copyright` - условия распространения
* `\h` - справка по операторам SQL
* `\?` - справка по командам psql
* `\g` или `;` в конце строки - выполнение запроса
* `\q` - выход

* `\l` - список баз данных
* `\c` {[БД|- ПОЛЬЗОВАТЕЛЬ|- СЕРВЕР|- ПОРТ|-] | conninfo} - подключиться к другой базе данных
    * `\c test_db test_user`
* `\conninfo` - информация о текущем соединении

* `\d` - список таблиц, представлений и последовательностей
* `\d имя` - описание таблицы, представления, последовательности или индекса

* `\du` - список ролей
* `\password имя` - безопасно сменить пароль пользователя

* `CREATE DATABASE название;` - создать БД
* `DROP DATABASE название;` - удалить БД

* `CREATE USER имя;` - создать пользователя
* `CREATE USER имя WITH PASSWORD пароль;` - создать пользователя с паролем
* `DROP USER имя;` - удалить пользователя

</details>

С помощью утилиты `psql` создал нового пользователя `dev` с паролем:

```bash
CREATE USER dev WITH PASSWORD 'qwerty';
```

Создал новую базу данных `todo_dev`:

```bash
CREATE DATABASE todo_dev;
```

## Подключение к базе данных из Go
Для подключения к БД из **Go** использовал стандартную библиотеку `database/sql`. Про особенности работы с данным пакетом кратко написано в [GO DATABASE/SQL TUTORIAL](http://go-database-sql.org/overview.html).

Создал директорию `internal/store` с файлами `db.go` и `config.go`.

В файле `config.go` определил структуру `Config` с полем `DatabaseURL` и конструктор `NewConfig`. 

Поскольку строка подключения к БД (`DatabaseURL`) содержит **пароль** (чувствительные данные), для ее передачи использовал **переменные окружения**.

Для загрузки переменных окружения из `.env` файла в структуру `Config` использовал библиотеку `joho/godotenv`.

```bash
go get github.com/joho/godotenv
```

А именно, вызвал функцию `godotenv.Load` в функции `Run`. А в конструкторе `NewConfig` использовал функцию `os.Getenv`, чтобы извлечь переменную окружения по ключу `DATABASE_URL`.

В файле `db.go` определил функцию `NewDB`, которая принимает `Config` и возвращает указатель `*sql.DB` и ошибку.

Замечу, что тип `sql.DB` - это **не соединение** с БД, это абстракция, которая позволяет не беспокоиться об организации **конкурентного доступа** к хранилищам.

`sql.DB` решает две задачи:
* Он открывает и закрывает соединения с фактической БД через **драйвер**
* Он управляет **пулом подключений**

Для работы с БД необходим драйвер. Для каждой СУБД есть свой драйвер.

В данном случае, я использовал драйвер `lib/pq` для подключения к PostgreSQL.

```bash
go get github.com/lib/pq
```

Чтобы методы библиотеки `lib/pq` не импортировались в проект, библиотеку импортировал **анонимно** (то есть использовать **alias** `_`).

Помним, что если в качестве псевдонима `_`, то будет вызвана функция `init` этого модуля (например, при подключении БД).

Итак, в файле `db.go` импортировал драйвер:

```go
import (
	"database/sql"

	_ "github.com/lib/pq"
)
```

В функции `NewDB` с помощью функции `sql.Open` создал объект `*sql.DB`. А также **пинганул** БД с помощью метода `db.Ping` (помним, что соединение с БД создается лениво, когда происходит первый вызов, поэтому для тестирования существует метод `Ping`).

## Миграции базы данных
Изменения в схеме БД (например, добавление новой таблицы) делаются с помощью **миграции**.

**Версионная миграция БД** - обновление структуры БД от одной версии до другой.

<details>
    <summary> Подробнее про миграции базы данных </summary>

* **Миграция базы данных** - это процесс изменения структуры и содержимого базы данных с целью обновления ее версии, переноса на другую платформу или слияния с другой базой данных.

* Это может включать добавление новых таблиц, изменение существующих таблиц, удаление таблиц или изменение типов данных.

* Миграция может потребоваться при обновлении версии СУБД или изменении платформы, на которой работает база данных.

* Необходимо проводить SQL-миграции с минимальным влиянием на работу приложения, т.е. изменять данные или схему данных таким образом, чтобы приложение продолжало работать и пользователи ничего не замечали.
</details>

Для написания и прогона миграций использовал утилиту `migrate`. Скачал исполняемый файл `.exe` для Windows из [последнего релиза](https://github.com/golang-migrate/migrate/releases) и указал путь до него в переменной окружения `Path`.

<details>
    <summary> Команды migrate</summary>

* `migrate create -ext sql -dir директория название` - создание миграции
* `migrate -path директория -database строка_доступа up` - прогон миграции для обновления БД
* `migrate -path директория -database строка_доступа down` - прогон миграции для отката версии БД
</details>

В моей БД три сущности (пользователи, списки, задачи), соответственно необходимо создать миграции для каждого объекта БД.

<p align="center">
    <img src="/assets/images/er_schema.png" width="800">
</p>

В частности, создал миграцию для работы с таблицей пользователей `create_users` командой:

```bash
migrate create -ext sql -dir migrations create_users
```

В директории `migrations` сгенерировалось два файла: с суффиксом `.up` для обновления БД и `.down` для отката версии БД. В этих файлах пишутся **SQL DDL запросы** с использованием операторов `CREATE`, `ALTER` и `DROP`.

Итак, в `.up` файле прописал SQL-запрос (DDL) для **создания** таблицы пользователей `users`, а в `.down` - для **удаления**.

Всего создал три миграции: `create_users`, `create_lists`, `create_tasks`.

Прогнал миграции командой:

```bash
migrate -path migrations -database "postgres://localhost/todo_dev?sslmode=disable&user=dev&password=qwerty" up
```

<details>
    <summary> Сводка по использованным типам данных </summary>

* `BIGSERAIL` - представляет **автоинкрементирующееся** числовое значение, которое занимает **8 байт**
    * Диапазон: `1` .. `9223372036854775807`
* `BIGINT` - целое число в большом диапазоне, которое занимает **8 байт**.
    * Диапазон: `-9223372036854775808` .. `9223372036854775807`
* `VARCHAR(n)` (`CHARACTER VARYING (n)`) - текст с ограничением по длине (максимальная длина строки может быть ограничена `n` **символов**).
    * Физически максимальный размер любых строк в PostgreSQL ограничен одним гигабайтом (`1GB`).
    * Логическое ограничение на максимальный размер строки (`char(n)`, `varchar(n)`, где `n` - логическое ограничение), задаваемое пользователем для конкретного поля, лимитирует количество символов в строке, а не длину строки в байтах. Поэтому, несмотря на физический лимит на максимальный размер строки в `1GB`, реальное максимальное количество символов в строке может быть меньше, так как различные кодировки символов могут использовать больше одного байта для представления одного символа.
* `TIMESTAMP` - подразумевал `timestamp without time zone` - дата и время (без часового пояса). Размер - **8 байт**.
    * `2004-10-19 10:23:54` - формат ввода **ISO 8601** (рекомендуемый формат).
    * `2004-10-19 10:23:54.789` - формат ввода **ISO 8601** с наносекундами.
    * `2004-10-19T10:23:54` - альтернативный формат **ISO 8601** для совместимости с **RFC 3339** и другими СУБД.
</details>

## Бизнес-сущности (слой Entity)
Слой `Entity` содержит **модели данных**, то есть структуры (с методами), которые являются представлениями записей в БД. Слой абсолютно независим и переносим.

Создал директорию `internal/entity` с файлами: `user.go`, `list.go`, `task.go`.

В файле `user.go` определил структуру **пользователя** с полями, соответствующими таблице `users` в БД. Также добавил дополнительное поле `Password` с не хэшированным паролем. Прописал `json` тэги для сериализации (процесса перевода структуры данных в битовую последовательность), при этом у поля `Password` установил опцию `omitempty`, чтобы пропускать пустое поле `Password`, а у поля `EncryptedPassword` - `-`, чтобы всегда пропускать поле `EncryptedPassword`.

В файле `list.go` определил структуру **списка** с полями, соответствующими таблице `lists` в БД.

В файле `task.go` определил структуру **задачи** с полями, соответствующими таблице `tasks` в БД. Поле `Deadline` будет храниться в формате `time.Time`, точнее в структуре `TimeISO`, для которой были переопределены методы `MarshalJSON` и `UnmarshalJSON`.

Это нужно, чтобы кодировать и декодировать дату и время в формате **ISO 8601** (в библиотеке `time` этот формат соответствует константе `time.DateTime` вида `2006-01-02 15:04:05`). Помним, что по умолчанию формат **RFC 3339**.

<details>
    <summary> Полезные функции/методы библиотеки time</summary>

* `func (t Time) MarshalJSON() ([]byte, error)` - реализует интерфейс `encoding.TextMarshaler`. `Time` - это строка в кавычках в формате **RFC 3339** с точностью до секунды.
* `func (t *Time) UnmarshalJSON(data []byte) error` - реализует интерфейс `encoding.TextUnmarshaler`. `Time` - это строка в кавычках в формате **RFC 3339** с точностью до секунды.

* `func Parse(layout, value string) (Time, error)` - разбирает отформатированную строку и возвращает значение времени, которое она представляет. 
    * `layout` - формат ввода. В качестве него можно передать константу `time.DateTime` (`2006-01-02 15:04:05`), формат которой совпадает с форматом метки времени в PosgreSQL.
* `func (t Time) Format(layout string) string` - возвращает текстовое представление значения времени, отформатированное в соответствии с форматом вывода (`layout`).
</details>

Итак, создал в директории `internal/entity` файл `timeiso.go`, в котором определил структуру времени с методами `MarshalJSON` и `UnmarshalJSON`.

## Интерфейсы хранилища и репозиториев
Сами модели данных не знают, как они сохраняются в БД, как они считываются из БД. За работу с БД отвечают **репозитории**. В данном проекте всего три репозитория (`UserRepository`, `ListRepository`, `TaskRepository`), которые соответствуют трем таблицам в БД.

Для удобства создал сущность **хранилища**, состоящее из репозиториев.

Хранилище (`Store`) - интерфейс, который скрывает детали реализации и предоставляет публичные методы, с помощью которых осуществляется работа с репозиторями из внешнего мира.

Итак, создал в директории `internal/store` файл `interfaces.go`, в котором описал **интерфейс хранилища** и **интерфейсы репозиториев**. 

В интерфейсе `Store` всего три метода: `User`, `List`, `Task`. Для удобства разработки сначала добавил только один метод `User`, который возвращает интерфейс `UserRepository` - репозиторий для работы с таблицей пользователей.

В интерфейсе `UserRepository` определил набор сигнатур методов: `Create`, `FindByID`, `FindByEmail`.

## Реализация интерфейса хранилища (слой Store)
В директории `internal/store` создал файл `store.go`, в котором определил реализацию интерфейса хранилища `AppStore`. А именно, структуру `Store` с приватным полем `userRepository` типа интерфейс `UserRepository`, конструктором `NewAppStore` и методом `User`, который возвращает интерфейс `UserRepository`.

Поскольку код организовал согласно **чистой архитектуре**, использовал **инъекцию зависимостей (dependency injection)** для обеспечения низкой связанности слоев. Для инъекции зависимости удобно использовать конструктор, который принимает интерфейс, а возвращает указатель на структуру, которую он создает.

В частности, конструктор `NewAppStore` принимает интерфейс репозитория и возвращает указатель на `AppStore`.

## Реализации интерфейсов репозиториев
В директории `internal/store` создал две директории `sqlrepository` и `testrepository` - это две реализации интерфейсов репозиториев.

`sqlrepository` будут непосредственно взаимодействовать с БД, а `testrepository` - реализации для тестового хранилища (**mock**).

Запросы непосредственно к БД нужны для тестов SQL-запросов внутри пакета `sqlrepository`.

А дополнительная реализации `testrepository` нужны при тестировании **вне пакета** `store` (например, `controller`), чтобы не делать реальные запросы к БД, а подменять БД на фейковую **in-memory** реализацию, которая хранит информацию в памяти (например, в `map`'е).

Это позволит упростить тесты, сделать их быстрее, дает возможность запускать их параллельно.

## Реализация sqlrepository
Итак, в директории `internal/store/sqlrepository` создал файлы `userrepository.go`.

В файле `userrepository.go` определяем структуру - реализацию интерфейса `UserRepository` с **приватным полем** типа `*sql.DB`, конструктором `NewUserRepository` и соответствующими методами.

<details>
    <summary> Замечания по реализации методов Create, FindByID, FindByEmail</summary>

1. Метод `Create`
    * Перед выполнением запроса в БД необходимо **валидировать модель пользователя** и **хэшировать пароль**, то есть требуется реализовать два дополнительных метода для структуры `User`.
    * Для запросов в БД, возвращающих только **одну строку** (single-row queries), существует короткая запись (связка методов `QueryRow` и `Scan`).
    * При добавлении строки в таблицу можно получить сгенерированный СУБД уникальный идентификатор этой строки (например, `user_id`) или значение любого поля, которое имеет значение по умолчанию, с помощью оператора `RETURNING`.
2. Метод `FindByID`
    * `SELECT` и связка методов `QueryRow` и `Scan`.
    * Чтобы **стандартизировать ошибки**, которые возвращают разные реализации репозиториев (`sqlrepository` и `testrepository`), создал кастомную ошибку `ErrRecordNotFound`. А именно в директории `internal/store` создал файл `error.go`, в котором определил новую ошибку с помощью функции `errors.New`.
        * Соответственно, в тестах проверял конкретную ошибку (вместо `assert.Error` использовал `assert.EqualError`).
3. Метод `FindByEmail`
    * Реализуется аналогично методу `FindByID`.

</details>

## Тестирование репозиториев в пакете sqlrepository
Помним, что хорошей практикой является написание тестов сразу после определения метода.

Для тестирования методов `Create`, `FindByID`, `FindByEmail` (и для методов других репозиториев, которые работают с БД) лучше использовать **реальную БД** , потому что ошибки могут возникнуть на уровне SQL-запросов, а с моками это **не отследить**.

Таким образом, перед тестированием необходимо было провести подготовительную работу.

В частности, создал тестовую БД `todo_test`:

```bash
CREATE DATABASE todo_test;
```

Прогнал для нее миграции:

```bash
migrate -path migrations -database "postgres://localhost/todo_test?sslmode=disable&user=dev&password=qwerty" up
```

Итак, в директории `internal/store/sqlrepository` создал файл `helper.go`, в котором определил вспомогательную функцию (**хэлпер**) `TestDB`, который будет возвращать объект `*sql.DB` для подключения к тестовой БД и **callback-функцию**, с помощью которой можно **очистить все таблицы**, которые будут заполняться в процессе тестов, чтобы новые тесты работали с пустой БД.

<details>
    <summary> Замечания по реализации хэлпера TestDB и библиотеке testing</summary>

* тип `testing.T` - тип, который передается всем тестовым функциям для управления состоянием тестов и поддержки форматированных логов для тестов.
* `t.Helper` - помечает вызываемую функцию, как хэлпер-функцию (она пропускается при выводе информации).
    * В частности, `t.Helper` вызывается в начале хэлпера `TestDB`.
* `t.Fatal` - тест провален.

* Чтобы удалить все строки из набора таблиц, а также из таблиц, ссылающихся по внешнему ключу на заданные таблицы, использовал команду `TRUNCATE` вместе с параметром `CASCADE`. Запрос обернул в функцию `fmt.Sprintf` и выполнил его с помощью метода `Exec`, поскольку запрос ничего не возвращает.
</details>

Кроме этого, создал файл `db_test.go`, в котором определил переменную `testDatabaseURL` и переопределил функцию `TestMain` из библиотеки `testing`, в которой происходит чтение переменной окружения `TEST_DATABASE_URL` (добавил ее в `.env` файл).

Функция `TestMain` вызывается один раз перед всеми тестами в конкретном пакете, поэтому в ней удобно проводить разовые манипуляции, в частности считать строку доступа до тестовой БД `todo_test`.

Замечу, что в функцию `TestMain` передается объект типа `*testing.M` - это тип, передаваемый функции `TestMain` для выполнения фактических тестов.

Помимо хэлпера `TestDB` создал хэлпер `TestUser`. А именно, в директории `internal/entity` создал файл `helper.go`, в котором определил хэлпер-функцию `TestUser`, которая нужна, чтобы в тестах каждый раз заново не определять структуру пользователя (не заполнять поля `Email` и `Password`).

После подготовительной части создал файл `userrepository_test.go`, в котором написаны тесты для методов структуры `UserRepository`.

<details>
    <summary> Полезные функции библиотеки stretchr/testify/assert</summary>

* `assert.NotNil` - проверка, что переданный указатель не `nil`.
* `assert.NotEmpty` - проверка, что переданный объект не пустой (не `nil`, `""`, `false`, `0`).

* `assert.NoError` - проверка, что переданная функция не вернула ошибку (а например, `nil`).
* `assert.Error` - проверка, что переданная функция вернула ошибку.
* `assert.EqualError` - проверка, что функция возвращает определенную ошибку.

* `assert.Equal` - проверка, что объекты одинаковы (например, ожидаемое и фактическое значение).
</details>

## Валидация модели пользователя и хэширование пароля
Помним, что в методе `Create` перед выполнением запроса в БД необходимо **валидировать модель пользователя** и **хэшировать пароль**, то есть требуется реализовать два дополнительных метода для структуры `User`.

В директории `internal/entity` в файле `user.go` определил метод `Validate`, в котором проверяется пользовательский ввод, чтобы нельзя было отправить что угодно и оно бы сохранилось в БД.

Кроме того, чтобы не хранить пароль в БД в открытом виде, определил callback-метод `BeforeCreate`, который вызывается при каждой попытке сохранить пользователя в БД с помощью метода `Create` репозитория `UserRepository`, а также приватную функцию `encryptString` для непосредственно шифрования строки `Password`.

Для хэширования использовал пакет `bcrypt` из библиотеки `x/crypto`:

```bash
go get golang.org/x/crypto
```

Чтобы сгенерировать хэш пароля с заданной стоимостью вычисления (параметр `cost`), использовал функцию `bcrypt.GenerateFromPassword`. В качестве значения `cost` была взята константа `bcrypt.MinCost = 4` (`bcrypt.DefaultCost = 10`).

<details>
    <summary> Замечания по параметру cost </summary>

* Параметр `cost` - это стоимость вычисления хэша.
* `cost` влияет на количество операций при генерации хэша, как степень числа 2.
    * При `cost = 10` будет $2^{cost} = 2^{10}$ повторений алгоритма для вычисления.
* Чем **выше стоимость** вычисления хэширующего алгоритма, тем **больше времени** требуется для взлома его вывода методом полного перебора (brute force).
* Таким образом, `cost` определяет количество циклов, через которое будет пропущена исходная информация (это **замедляется** процесс хэширования).
</details>

Добавил в файл `user_test.go` тест `TestUser_BeforeCreate` для метода `BeforeCreate`.

Для валидации модели данных пользователя использовал библиотеки `go-ozzo/ozzo-validation` и `go-ozzo/ozzo-validation/is`:

```bash
go get github.com/go-ozzo/ozzo-validation
go get github.com/go-ozzo/ozzo-validation/is
```

Импортировал их в файл `user.go`:

```go
import (
    validation "github.com/go-ozzo/ozzo-validation"
    "github.com/go-ozzo/ozzo-validation/is"
)
```

<details>
    <summary> Замечания по реализации метода Validate</summary>

Для валидации полей структуры `User` использовал функцию `validation.ValidateStruct`, в которую передал указатель на структуру `User` и объекты типа `*validation.FieldRules`, которые возвращает функция `validation.Field`, принимающая указатель на поле структуры, которое необходимо валидировать, и правила проверки.

В частности, поле `Email` **обязательное** (правило `validation.Required`) и является **почтовым адресом** (правило `is.Email` из библиотеки `is`).

Для валидации пароля пользователя `Password` создал **кастомное правило** с помощью функции `validation.By`.

Идея в том, что **при добавлении** пользователя в БД поле пароля `Password` обязательно, но **при чтения** пользователя из БД в `Password` ничего не записывается, так как пароль не хранится в открытом виде в БД. Следовательно, если поле будет обязательным, то при попытке изменить пользователя и сохранить его в БД, модель будет не валидна, поскольку поле `Password` будет пустым.

Итак, создал в директории `internal/entity` файл `validations.go`, в котором определил функцию `requiredIF`, которая устанавливает условие на обязательность поля и возвращает `validation.RuleFunc`. В данном случае, если поле `EncryptedPassword` еще пустое (`""`), то в функцию `requiredIF` передается `true` и правило принимает значение `validation.Required`.

Кроме этого, проверил длину пароля правилом `validation.Length`.
</details>

Также добавил в файл `user_test.go` тест `TestUser_Validate` для метода `Validate`.

<details>
    <summary> Замечание по реализации модульных тестов</summary>

Для табличных тестов:
1. Определил **срез анонимных структур** `testCases` с полем названия **sub-теста** (`name`) и дополнительными полями.
    * Например, для теста метода `Validate` дополнительные поля:
        * `u` - функция, которая возвращает пользователя, внутри нее можно делать манипуляции над тестовым валидным пользователем.
        * `isValid` - `bool`.
2. Создал **цикл**, который итерирует по всем sub-тестам и запускает их.

Псевдо-код unit-тестов:

```go
func TestStruct_Func(t *testing.T) {
    testCases := []struct {
        name: string,
        // ...
    }

    for _, tc := range testCases {
        t.Run(tc.name, func(t *testing.T) {
            // ...
        })
    }
}
```
</details> 

В директории `internal/store/sqlrepository` в файле `userrepository.go` вызвал методы `Validate` и `BeforeCreate` для валидации и хэширования пароля в методе `Create`.

Запустил еще раз тест `TestUserRepository_Create`, чтобы убедиться, что все работает.

## Реализация и тестирование testrepository
Создал еще одну реализацию репозиториев, которая будет использоваться в тестах других пакетов.

Итак, создал директорию `internal/store/testrepository` с файлом `userrepository.go`.

В файле `userrepository.go` определил структуру - реализацию интерфейса `UserRepository` с **приватным полем** `users` типа `map[int]*entity.User`, конструктором `NewUserRepository` и соответствующими методами. В методах `FindByID` и `FindByEmail`, если пользователь не найден, возвращал **кастомную ошибку** `store.ErrRecordNotFound`.

Также создал файл `userrepository_test.go` с тестами методов репозитория `UserRepository`.

Таким образом, реализация `testrepository` в отличие от `sqlrepository` вместо объекта `*sql.DB` для подключения к БД содержит `map`'у - **in-memory** хранилище пользователей, где ключом является `UserID`, а значением структура пользователя.

Тесты репозиториев аналогичны тестам в `sqlrepository`.

## Бизнес-логика (слой UseCase)
Слой `UseCase` содержит конкретные варианты использования приложения (минимальное количество кода). В данном слое работаем с абстракциями.

Итак, создал директорию `internal/usecase` с файлами `interfaces.go` и `usecase.go`.

В файле `interfaces.go` описал интерфейс `UseCase`, определяющий пока только сигнатуры методов репозитория `UserRepository` (перед названиями префикс `Users`).

Согласно **чистой архитектуре** провел **инъекцию зависимостей (dependency injection)**. В частности, в файле `usecase.go` создал структуру `AppUseCase` с приватным полем `store` типа интерфейс хранилища, конструктором `NewUseCase`, который принимает интерфейс хранилища и возвращает указатель на `AppUseCase` и соответствующими методами.

Также создал файл `usecase_test.go` с тестами методов структуры `AppUseCase`.

В директории `internal/controller/apiserver` в файле `apiserver.go` добавил в структуру сервера приватное поле `uc` типа интерфейс `UseCase`, а в конструктор `NewServer` - новый параметр - интерфейс `UseCase`.

Также поправил тест обработчика `handleHello` и добавил вызов конструкторов `NewStore` и `NewAppUseCase` в функции `Run` в директории `internal/app`.

## Структура REST API
Перед тем, как описать публичные и приватные endpoint'ы нашего сервера, вспомним **базовые понятия REST API**.

<details>
    <summary>REST API</summary>

* **API (Application Programming Interface, программный интерфейс приложения)** - это набор способов и правил, по которым различные программы общаются между собой и обмениваются данными.
    * Основной задачей API является **создание связи между двумя приложениями**.
    * Взаимодействие осуществляется через **JSON**, а данные получаем в приложениях с помощью API-запросов.
* **REST (Representational State Transfer) API** - это **архитектурный стиль** взаимодействия компонентов распределённого приложения в сети, основанный на методах протокола HTTP.
* **6 принципов REST**:
    1. Клиент-серверная архитектура
    2. Stateless
    3. Кэширование
    4. HATEOAS (единообразие интерфейса)
    5. Layered system (слоистая архитектура)
    6. Code on demand (код по требованию)
* Подробнее [здесь](https://habr.com/ru/articles/590679/)
</details>

<details>
    <summary> routes, HTTP-methods, endpoints</summary>

* **route (роут - маршрут)** - это **имя**, которое отсылает работу API к определенным endpoint'ам.
    * Если упростить, то можно сказать, что маршрут - это **URI адрес** запрашиваемого ресурса (точнее **path**), к которому можно обратиться разными HTTP методами.
    * Маршрут может иметь несколько endpoint'ов.
* **Пространство имён** - это начальная часть маршрута (префикс маршрута).
* **HTTP-метод** - это **тип действия**, которое клиент хочет выполнить над ресурсом.
* **endpoint (эндпоинт - конечная точка)** - это само **обращение** к маршруту отдельным HTTP методом.
    * endpoint выполняют конкретную задачу, принимают параметры и возвращают данные клиенту.
* `endpoint = HTTP-method + route (aka URI)`
* Подробнее [здесь](https://wp-kama.ru/handbook/rest/basic)
</details>

Еще раз, REST API - это **не протокол**, а лишь **архитектурный подход** к построению web-приложений, которые общаются по протоколу HTTP.

В данном дизайне системе все взаимодействие с сервером сводится к **CRUD-операциям**, которые включают в себя 4 функции:
1. CREATE (cоздание данных)
2. READ (чтение данных)
3. UPDATE (редактирование данных)
4. DELETE (удаление данных)

**CRUD** - это короткое название всех видов операций маршрута, которые он позволяет делать: создавать, читать, обновлять и удалять что-либо (ресурс).

Для каждого типа операций используется отдельный **HTTP-метод**:
1. `POST` - создание
    * не безопасный, не идемпотентный
2. `GET` - чтение
    * безопасный, идемпотентый
3. `PUT/PATCH` - редактирование
    * `PUT` - полная замена изменяемого объекта (идемпотентный)
    * `PATCH` - частичное изменение объекта
4. `DELETE` - удаление
    * идемпотентый

<details> 
    <summary> Безопасный и идемпотентный запрос</summary>

* **Безопасный (safe)** - не меняет данные, а только запрашивает.
* **Идемпотентный (idempotent)** - один и тот же запрос всегда возвращает одинаковый результат (до тех пор, пока сами данные не поменялись).
</details>

Безопасность REST API (доклад с кибербеза) // TODO

**Общая структура route (URI):**
```
/:entity[/:id][/?:params]
```
* `entity` - название сущности, например, класса или таблицы/представления в БД.
    * В частности: `users`, `lists`, `tasks`.
* `id` *opt*. - первичный ключ объекта.
    * Если первичный ключ составной, то части указываются через `/`
        * В частности: `/users/10`, `/dictionary/ru/apptitle`
* `params` *opt*. - дополнительные параметры выборки для списочных запросов (фильтрация, сортировка, пагинация и пр.).
    * Форматируются по правилам HTTP GET параметров (функции encodeURIComponent и пр.)

Подробнее [здесь](https://itnan.ru/post.php?c=1&p=447322)

Использование REST API подхода при создании серверных (backend) приложений позволяет **не зависеть от конкретной реализации клиента** (браузер, мобильное приложение, Postman, curl).

**Структура REST API:**  
**Публичные endpoint'ы**, доступные всем:
```
POST /users - регистрация пользователя
POST /tokens - аутентификация пользователя и выдача JWT
```

**Приватные endpoint'ы**, доступные только аутентифицированным пользователям:
```
GET /profile - просмотр профиля пользователя

GET /lists - просмотр всех списков

POST /lists - создание списка
GET /lists/{id} - просмотр списка
PUT /lists/{id} - редактирование списка
DELETE /lists/{id} - удаление списка

POST /lists/{id}/tasks - добавление задачи в список
GET /lists/{id}/tasks - просмотр всех задач в списке

GET /tasks/{id} - просмотр задачи в списке
PUT /tasks/{id} - редактирование задачи в списке  
DELETE /tasks/{id} - удаление задачи из списка
```

## Endpoint для регистрации пользователя
В директории `internal/controller/apiserver` в файле `apiserver.go` определил endpoint для регистрации пользователя - метод `handleUsersCreate`, который будет создавать пользователя в БД.

Как уже отмечалось при создании тестового обработчика `handleHello`, удобно использовать не привычную функцию с сигнатурой (`func(w http.ResponseWriter, r *http.Request)`), а функцию, возвращающую функцию типа `http.HandlerFunc`.

В методе `handleUsersCreate` перед `return` определил структуру запроса `request`, в ней описал поля, которые ожидаются от пользователя во время регистрации. Сразу прописал `json` тэги для сериализации.

Далее в теле возвращаемой функции, которая используется для каждого запроса, создал указатель на структуру `request`, которую попытался заполнить информацией, декодированной из payload'а запроса. Для **декодирования JSON-данных** использовал библиотеку **json** (связка функции `NewDecoder` и метода `Decode`).

Определил два приватных хэлпер-метода `error` и `respond`.

Чтобы удобно **рендерить ошибку**, которая могла произойти при работе обработчика, использовал метод `error`. Сигнатура метода: `error(w http.ResponseWriter, r *http.Request, code int, err error)`. Метод не является полностью самостоятельным, а использует второй хэлпер `respond`.

Хэлпер `respond` - более абстрактный, используется для **рендеринга всех ответов**. По сути кодирует структуры обратно в JSON. Для **кодирования данных в JSON** использовал библиотеку **json** (связка функции `NewEncoder` и метода `Encode`). Сигнатура метода: `respond(w http.ResponseWriter, r *http.Request, code int, data interface{})`. Метод принимает те же параметры, что и `error` кроме ошибки, вместо этого поле данных `data`, которое может быть любым, поэтому его тип `interface`. Для записи статус кода использовал метод `w.WriteHeader`.

Итак, в случае ошибки декодирования запроса, вызывал метод `error` со статус-кодом `400` (`http.StatusBadRequest`) и `return`.

<details>
    <summary>Сводка по использованным статус-кодам</summary>

**Статус-код** - это машиночитаемое описание **результата HTTP-запроса** в виде трёхзначного числа.

Все статус-коды делятся на **пять больших групп**:
* `1xx` - информационные (фактически, какое-то хождение имеет разве что `100 Continue`)
* `2xx` - коды успеха операции
* `3xx` - коды перенаправлений (индицируют необходимость выполнения дополнительных действий, чтобы считать операцию успешной)
* `4xx` - клиентские ошибки
* `5xx` - серверные ошибки

[Источник](https://habr.com/ru/articles/739808/)

Таблица. Использованные статус-коды из библиотеки net/http
| Статус-код | Описание |
| ---------- | -------- |
| StatusBadRequest | 400 |
| StatusUnauthorized | 401 |
| StatusUnprocessableEntity | 422 |
| StatusCreated | 201 |
| StatusOK | 200 |
| StatusInternalServerError | 500 |

[Источник](https://habr.com/ru/companies/piter/articles/511382/)
</details>

Далее создал структуру пользователя, передал в нее параметры из запроса и вызвал usecase `UsersCreate` для создания записи о новом пользователе в БД. Если пользовател передал не валидные данные, возвращал статус-код `422` (`http.StatusUnprocessableEntity`). Если все корректно, вызывал хэлпер `respond` со статус-кодом `201` (`http.StatusCreated`).

Перед вызовом `respond`, необходимо стереть приватное поле `Password`, которое не надо рендерить (помним, про `json` тэги у структуры пользователя). Для этого в директории `internal/entity` в файле `user.go` определил метод `Sanitize`.

Также в методе `configureRouter` с помощью метода `HandleFunc` у поля `s.router` зарегистрировал endpoint `handleUsersCreate` на обработку `POST` запросов на маршрут `/users`.

В заключение добавил в файл `apiserver_internal_test.go` тест `TestServer_HandleUsersCreate`.

<details>
    <summary> Замечания по реализации модульного теста метода handleUsersCreate</summary>

Как уже отмечалось, для модульных тестов:
1. Определил **срез анонимных структур** `testCases` с полем названия **sub-теста** (`name`) и дополнительные поля:
    * `payload` - `interface{}`, может быть любым типом данных (например, `map[string]string`).
    * `expectedCode` - `int`, в данном случае не имеет смысла проверять сам ответ JSON, так как это может со временем меняться, поэтому проверяем только статус-код.
2. Создал **цикл**, который итерирует по всем sub-тестам и запускает их.

Замечу, что для передачи `payload` в `NewRequest` необходимо закодировать ее в JSON. Для этого создал указатель на переменную типа `bytes.Buffer` и использовал связку функции `NewEncoder` и метода `Encode`.
</details>

После сборки проекта отправил два тестовых запроса с помощью утилиты `curl`.

Невалидный:

```bash
curl --location --request POST http://localhost:8080/users \
--data-raw '{
    "email":"invalid"
}'
```

Валидный:

```bash
curl --location --request POST http://localhost:8080/users \
--data-raw '{
    "email":"user@example.org",
    "password":"password"
}'
```

<details>
    <summary> Сводка по опциям curl</summary>

* `--location` (`-L`) - выполнять перенаправления (redirect)
* `--request` (`-X`) - использовать HTTP-метод
* `--header` (`-H`) - установить HTTP-заголовок
* `--data-raw` - отправить указанные данные в POST запросе
    * тоже самое что `--data` (`-d`), но не имеет специальной интерпретации символа `@`
* `--verbose` (`-v`) - подробный вывод запросв и ответв (вместе с заголовками)
</details>

Замечу, что на Windows требуется экранировать кавычки (`" "`) слэшами (`\" \"`), а для записи запроса в несколько строк используется символ `^`.

## Принцип Stateless
Помним, что **принципы REST** помогают добиться следующих **нефункциональных требований**:
* Производительность
* Масштабируемость
* Гибкость к изменениям
* Отказоустойчивость
* Простота поддержки

**Stateless** - одно из этих ограничений, относится к способу **управления состоянием** в архитектуре приложения.

Итак, рассмотрим различия между **Stateful** и **Stateless** архитектурами.
1. **Stateful** система **сохраняет состояние** на сервере. Под состоянием следует понимать информацию о предыдущих взаимодествиях с клиентами (например, информацию о предыдущих запросах).
    * В частности, на сервере могут храниться **сессии пользователей** в качестве **состояния аутентификации** пользователей.
    * <details>
        <summary> Stateful (похожее определение)</summary>

        * **Stateful** приложение, пока работает, сохраняет на сервере какие-то данные (например, информацию о предыдущих запросах) как состояние внутри себя.
        * [Источник](https://habr.com/ru/articles/648101/)
    </details>
2. **Stateless** система **не сохраняет состояние** на сервере, а перекладывает эту ответственность на клиентскую часть. Каждый запрос рассматривается как отдельное, изолированное взаимодействие.
    * Принцип заключается в том, что сервер не должен хранить у себя информацию о предыдущих взаимодействиях с клиентом. Он должен в каждом запросе получать всю информацию, необходимую для обработки.
    * В частности, сервер может сгенерировать и передать пользователю **токен для аутентификации**. В каждом запросе клиент будет передавать токен, а сервер валидировать его и в случае успеха предоставлять пользователю доступ к ресурсу.

> **Stateful** подход **ограничивает горизонтальную масштабируемость** системы, поэтому он **не используется** при разработке распределенных, отказоустойчивых **REST-сервисов**.

<details> 
    <summary> Подробнее про горизонтальное и вертикальное масштабирование</summary>

**Масштабирование:**
1. **Горизонтальное**
    * Увеличение количества серверов, параллельно выполняющих одну и ту же функцию.
2. **Вертикальное**
    * Увеличение производительности каждого компонента системы с целью повышения общей производительности (улучшение железа).
    * Оптимизация алгоритмов (работа за меньшее асимпотическое время).
</details>

<details>
    <summary> Подробнее про проблемы горизонтального масштабирования Stateful систем в контексте монолита и микросервиса</summary>

Когда у сервиса миллионы клиентов, один сервер не сможет всех их обслужить, поэтому развертывают **множество экземпляров сервиса** на разных серверах. Перед ними ставится **балансировщик нагрузки (load balancer)**, который распределяет запросы по серверам.

Соответственно, клиент при каждом запросе может попадать на разную копию сервера, и **в случае Stateful подхода состояние об аутентификации пользователя будет теряться**, поскольку на одном сервере это состояние будет хранится, а на копиях - нет.

Чтобы определить **сколько экземпляров сервиса развернуть**, необходимо посмотреть по логам **RPS** (request per second, количество запросов в секунду).

Для **монолитной архитектуры** эта проблема решается **выносом состояния** на отдельный **кэш-сервер**. Например, **Redis** - быстрое хранилище данных типа «ключ‑значение» в памяти (in-memory key-value БД). Однако для **микросервиса** эта неправильно, поскольку хорошая архитектура микросервиса подразуемвает **разделение уровней хранилища** (микросервис #1 не должен обращаться к хранилищу, к которому обращается микросервис #2).

Напомню, что **микросервис** начинает превращаться в **монолит**, когда происходит **смешивание функциональности**.
</details>

Итак, **использование принципа Stateless в REST-архитектуре** дает:
1. **Горизонтальную масштабируемость сервера**
    * Каждый запрос обрабатывается независимо и хранить состояние на сервере не требуется.
2. **Простоту тестирования**
    * Нет сложностей с воспроизведением состояния во время автоматизированных тестов, поскольку в Stateless подходе - это заранее определенная структура. Например, JSON с определенными полями, о значении которых все известно.
3. **Простоту поддержки**
    * По логам можно отследить, какой запрос приходил от клиента, какой ответ он получил. Не требуется дополнительно узнавать о том, какое состояние хранил сервер.
4. **Высокую отказоустойчивость**
    * Отказ в одном компоненте не повлияет на остальные.
5. **Уменьшение времени обработки запроса**
    * Не требуется отправлять запросы в БД или кэш, чтобы посмотреть состояние.
6. Возможность использовать **кэширование**.

**Недостатки Stateless:**
1. **Увеличение нагрузки на сеть**
    * Каждый запрос требует передачу **полной информации**, всего контекста, необходимого для обработки.
2. **Усложнение логики клиента**
    * Именно **на стороне клиента** нужно хранить всю информацию о состоянии, о допустимых и недопустимых действиях и т.д.

## Стандарт JSON Web Token (JWT)
Stateful и Stateless подходам соответствуют два типа **аутентификации**:
* **Сессиями** (stateful)
* **Токенами** (stateless)

<details>
    <summary> Идентификация - Аутентификация - Авторизация</summary>

* **Идентификация** (Определение)
    * Кто ты?
* **Аутентификация** (Проверка подлинности)
    * Чем докажешь?
    * Статус-код: `401` (`Unauthorized`)
        * Не аутентифицирован (название может запутать!) 
* **Авторизация** (Предоставление доступа)
    * Входи!
    * Статус-код: `403` (`Forbidden`)
        * Доступ запрещен / нет прав доступа
</details>

Соответственно, в данном приложении используются токены.

Перед тем, как разобрать алгоритм аутентификации через токены, полезно рассмотреть, как работают сессии.

<details>
    <summary> Подробнее про сессии (алгоритм аутентификации, особенности)</summary>

**Алгоритм аутентификации через сессии:**
1. Пользователь отправляет на сервер логин и пароль.
2. Сервер проверяет данные в БД.
3. Сервер создает сессию на своей стороне и сохраняет ее в `SessionStore`, далее передает пользователю **ID сессии** в заголовке `Set-Cookie` (это и есть сессионная кука - **HTTP-cookie**).
4. Пользователь отправляет cookie при каждом запросе в заголовке `Cookie`.
5. Сервер валидирует ее и дает пользователю доступ на основании сессии.
6. Когда пользователь выходит из системы, сервер удаляет сессию из `SessionStore`.

**Сессии хранятся на стороне сервера (stateful)**:
* В памяти
* БД (напр. Postgres / Mongo)
* Кэш (напр. Redis / Memcached)

**Каждый пользователь идентифицируется по ID сессии**:
* Непрозрачные данные, третья сторона не может извлечь из них никакой информации. Только сервер может связать ID сессии и пользователя.
* Чаще всего храниться в cookie и используется в **Server-side Rendering (SSR)** приложениях.

[Источник](https://www.youtube.com/watch?v=w8ENQfaYIT8)
</details>

<details>
    <summary> Подробнее про HTTP-cookie</summary>

**HTTP-cookie:**
* Такой же HTTP заголовок, как и другие (напр. `User-Agent` или `Content-Type`).
* Используется для контроля сессий, персонализации и хранения пользовательских настроек, а также трекинга пользователей.
* Состоит из имени и значения, а также (опционально) атрибутов/флагов.
* Сервер посылает cookie в заголовке `Set-Cookie`.
* Браузер (клиент) посылает cookie в заголовке `Cookie`.

**Пример ответа от сервера:**

```
HTTP/1.1 200 OK
Content-Type: text/html
Set-Cookie: session-id=M1bGviyM4o5QEuAr7ioFsaf24aq;
Expires=Fri, 5 Oct 2018 14:28:00 GMT;
Domain= example.com ; Path=/
```

[Источник](https://www.youtube.com/watch?v=w8ENQfaYIT8)
</details>

**Алгоритм аутентификации через токены:**
1. Пользователь отправляет логин и пароль.
2. Сервер проверяет данные в БД.
3. Сервер генерирует и подписывает **токен**, в который "зашивает" данные для идентификации пользователя (**ID пользователя**), далее передает пользователю токен в заголовке `Set-Cookie`.
4. Пользователь сохраняет токен на своей стороне и посылает его при каждом последующем запросе в заголовке `Authorization` (`Authorization: Bearer токен`).
5. Сервер валидирует токен и дает пользователю доступ к ресурсу.
6. Когда пользователь выходит из системы, токен удаляется с клиента (но остается валидным).

**Токены:**
* Токены хранятся на стороне клиента, сервер ничего не сохраняет (**stateless**).
* Сервер **подписывает** токены с использованием **секрета** (с помощью алгоритма `HMAC`) или **пары открытого/закрытого ключей** с использованием алгоритма `RSA` или `ECDSA`.
* Сервер посылает токен в заголовке `Set-Cookie`.
* Клиент посылает токен в заголовке `Authorization` (`Authorization: Bearer токен`).
* Зачастую используются в **Single-page Application (SPA)**, **API** для веб и мобильных приложений.
* Генерируется 2 токена: **Access** & **Refresh**:
    * **Access** токен имеет **малое время жизни** (напр. 15 минут), используется для доступа к ресурсам.
    * **Refresh** токен имеет **большое время жизни** (напр. 30/60 дней), посылается на отдельный endpoint для обновления Access токена, чтобы пользователю не надо было заново вводить логин и пароль.
* Лучше всего хранить токены в **HttpOnly cookie**. Однако часто они хранятся в **localStorage** / **sessionStorage**, которые уязвимы к **Cross-site scripting (XSS)** атакам.

Далее рассмотрим **JSON Web Token (JWT)** - открытый **стандарт** для создания токенов, основанный на формате **JSON**.

Перед этим советую прочитать отличное [Введение в JSON Web Tokens](https://jwt.io/introduction) от **JWT.io**.

**Стандарт JWT:**
* **JSON Web Token (JWT)** - это открытый **стандарт** (**RFC 7519**), который определяет компактный и автономный способ безопасной передачи информации между сторонами в виде объекта **JSON**.
* Эта информация может быть проверена и ей можно доверять, поскольку она имеет **цифровую подпись**.
* Подпись бывает **симметричная** (секрет) и **асимметричная** (публичный/приватный ключ).
    * **Симметричные** методы (например, алгоритм `HMAC`) используют только **один секрет**.
    * **Асимметричные** методы (например, алгоритмы `RSA`/`ECDSA`) используют **разные ключи** для подписи и валидации токенов.

Итак, **JWT-токен** - это просто **объект JSON**, **подписанный** его автором, благодаря этому определяются две вещи, касающиеся данных:
* Автор токена владел секретом подписи.
* Данные не были изменены с момента их подписания.

Токен состоит из трех частей, разделенных точками (`.`) и закодированных в `base64url`, и выглядит так: `xxxxx.yyyyy.zzzzz`. Первые две части - это **JSON объекты**, а последняя - **подпись**.

<details>
    <summary> base64url</summary>

`base64url` - разновидность `base64` (стандарт кодирования двоичных данных при помощи только 64 символов **ASCII**).
</details>

**Структура JWT-токена:**
1. `header`
    * Заголовок является **служебной частью** и содержит необходимую информацию для проверки последней части - подписи.
    * Обычно состоит из **двух полей**:
        1. `alg` - алгоритм хэширования подписи (в данном случае, `HS256` означает `HMAC-SHA256`).
            * Использование алгоритма `none` указывает на то, что токен не был подписан. В подобном токене отсутствует часть с подписью, и установить его подлинность невозможно.
        2. `typ` - тип токена (в данном случае, `JWT`)
        
    * 
        ```json
        {
            "alg": "HS256",
            "typ": "JWT"
        }
        ```
    * Этот JSON кодируется в `base64url` для формирования **первой части** JWT.

2. `payload` (`claims`)
    * Полезная нагрузка содержит **полезные данные**, которые хранятся внутри JWT. Эти данные также называют **JWT-claims** (заявки).
    * Есть три типа `claims`:
        * **Registered** - набор предопределенных полей согласно стандарту **RFC 7519**
            <details>
            <summary> Список зарезервированных полей</summary> 
            
            * `iss` (issuer) - издатель токена
            * `sub` (subject) - “тема”, назначение токена
            * `aud` (audience) - аудитория, получатели токена
            * `exp` (expire time) - срок действия токена (**время жизни токена**)
            * `nbf` (not before) - срок, до которого токен не действителен
            * `iat` (issued at) - время создания токена
            * `jti` (JWT id) - идентификатор токена
            </details>
        
        * **Public**
        * **Private**
    * 
        ```json
        {
            "exp": 1505467756869,
            "iat": 1505467152069,
            "user": 1,
            "admin": true
        }
        ```
    * Поскольку `payload` **не шифруется**, в нем **нельзя передавать чувствительные данные** (например, пароли). Обычно передают **набор ролей** и **ID пользователя**.
    * Этот JSON также кодируется в `base64url` для формирования **второй части** JWT.
3. `signature`
    * Подпись используется для проверки того, что сообщение (`payload`) **не было изменено**. Если кто-то попытается **изменить данные** в токене, то он станет **не валидным**.
    * Для создания подписи, закодированные в `base64url`, `header` и `payload` соединяются через точку (`.`). Затем полученная строка **хэшируется** алгоритмом, заданным в `header` на основе **секретного ключа**.
    * Процесс создания подписи `HMAC SHA256` алгоритмом можно описать следующим псевдо-кодом:
    ```
    HMACSHA256(
        base64UrlEncode(header) + "." +
        base64UrlEncode(payload),
        secret)
    ```
    * Этот JSON также кодируется в `base64url` для формирования **последней части** JWT.

Объединив три компонента, получим JWT-токен:

```
base64UrlEncode(header) + '.' + base64UrlEncode(payload) + '.' + base64UrlEncode(signature)
```

<details>
    <summary> Сессии vs Токены</summary>

**Сессии vs Токены:**
* Сервер не имеет никакого контроля над токенами.
    * Например, если произошла утечка токенов, сервер никак не может их инвалидировать. Он может только поменять ключ-подписи, тогда все токены, которые были выпущены станут невалидными.
* Сессии хранятся на сервере, что добавляет небольшой overhead (дополнительные запросы в БД).
* Сессии сложнее масштабируются горизонтально из-за stateful дизайна.
* Сессии не могут использоваться между разными доменами.
* Токены позволяют реализовать слабосвязную архитектуру и использовать как для веб-интерфейсов, так и мобильных приложений и т.д.
* Чтобы иметь возможность аннулировать токены, сервер может хранить blacklist / whitelist токенов, но тогда это становится stateful.
[Источник](https://www.youtube.com/watch?v=w8ENQfaYIT8)
</details>

## Endpoint для аутентификации пользователя и выдачи JWT
В директории `internal/controller/apiserver` в файле `apiserver.go` определил endpoint для аутентификации пользователя - метод `handleTokensCreate`, который будет **проверять логин и пароль** и, если они верны, **генерировать JWT-токен** для пользователя.

Для работы с JWT использовал библиотеку `golang-jwt/jwt`:

```bash
go get github.com/golang-jwt/jwt/v5
```

Снова обработчик `handleTokensCreate` - это не привычная функция с сигнатурой (`func(w http.ResponseWriter, r *http.Request)`), а функция, возвращающая функцию типа `http.HandlerFunc`.

По аналогии с обработчиком регистрации в методе `handleTokensCreate` перед `return` определил структуру запроса `request`. В ней описал поля, которые ожидаются от пользователя во время аутентификации. Сразу прописал `json` тэги для сериализации.

Кроме того, для записи поля `UserID` в payload JWT определил структуру `tokenClaims` с полем `UserID` типа `int` и анонимным полем типа `jwt.RegisteredClaims`.

Структура типа `jwt.RegisteredClaims` содержит зарезервированные поля, в частности **время жизни токена** `ExpiresAt`.

По аналогии с обработчиком регистрации в теле возвращаемой функции создал указатель на структуру `request`, которую попытался заполнить информацией, декодированной из payload'а запроса (связка функции `NewDecoder` и метода `Decode`из библиотеки **json**). В случае ошибки декодирования запроса, вызывал метод `error` со статус-кодом `http.StatusBadRequest`.

Далее попытался найти пользователя в БД по `Email` (вызвал `usecase` `UsersFindByEmail`) и проверил, что пароль соответствует зашифрованному в БД (вызвал метод пользователя `ComparePassword`).

В директории `internal/entity` в файле `user.go` определил **вспомогательный метод** `ComparePassword` для сравнения паролей, в котором вызвал функцию `bcrypt.CompareHashAndPassword`.

В случае ошибки вызывал метод `error` со статус-кодом `401` (`http.StatusUnauthorized`) и `return`. При этом создал **абстрактную ошибку** `errIncorrectEmailOrPassword`, чтобы не передавать информацию о том, что пользователь не найден (например, чтобы злоумышленники не начали брутфорсить email). А именно в этом же файле `apiserver.go` определил кастомную ошибку с помощью функции `errors.New`.

Если пользователь аутентифицировался, необходимо выдать ему токен, поэтому далее создал структуру `claims` типа `tokenClaims` с полями `UserID` и `ExpiresAt`.

Для установки срока действия токена `ExpiresAt` в 5 мин использовал функцию `jwt.NewNumericDate` и библиотеку `time` (связка функции `Now`, метода `Add`).

Затем **создал токен** с помощью функции `jwt.NewWithClaims`, в которую передал метод подписи `jwt.SigningMethodHS256` (это симметричный метод `HMAC SHA256`) и структуру `claims`.

Далее **подписал токен** с помощью метода `SignedString`, в который передал секретный ключ.

Так как использовал алгоритм хэширования `SHA256`, то секретный ключ должен быть длиной минимум **32 символа** (`32 * 8 бит = 256 бит`). Для генерации использовал [Encryption key generator](https://generate-random.org/encryption-key-generator?count=1&bytes=32&cipher=aes-256-cbc&string=&password=).

Для передачи секрета использовал **переменные окружения**, в частности добавил новое поле `SecretKey` в конфиг сервера, а в конструкторе `NewConfig` использовал функцию `os.Getenv`, чтобы извлечь переменную окружения по ключу `SECRET_KEY`.

Замечу, что при использовании `HMAC` алгоритма секрет [требуется](https://golang-jwt.github.io/jwt/usage/signing_methods/#signing-vs-encryption) передать в формате `[]byte`.

Если при подписи токена возникла ошибка, возвращал статус-код `500` (`http.StatusInternalServerError`).

Чтобы **передать токен** в заголовке `Set-Cookie`, использовал функцию `http.SetCookie`, в которую передал `w` и `http.Cookie`.

В конце вызывал хэлпер `respond` со статус-кодом `200` (`http.StatusOK`).

Также в методе `configureRouter` с помощью метода `HandleFunc` у поля `s.router` зарегистрировал endpoint `handleTokensCreate` на обработку `POST` запросов на маршрут `/tokens`.

В заключение добавил в файл `apiserver_internal_test.go` тест `TestServer_HandleTokensCreate`. При этом, срез анонимных структур `testCases` содержит те же поля, как и в тесте регистрации.

После сборки проекта отправил несколько тестовых запросов с помощью утилиты `curl`.

Невалидные:

```bash
curl --location --request POST http://localhost:8080/tokens \
--data-raw '{
    ""
}'
```

```bash
curl --location --request POST http://localhost:8080/tokens \
--data-raw '{
    "email":"user@example.org",
    "password":"invalid"
}' -v
```

Валидный:

```bash
curl --location --request POST http://localhost:8080/tokens \
--data-raw '{
    "email":"user@example.org",
    "password":"password"
}' -v
```

## Middleware-компоненты. Пакет context
Небольшое отступление перед написанием middleware-компонентов для:
1. Проверки аутентификации пользователя по JWT
2. Добавления правильных CORS-заголовков
3. Добавления уникального идентификатора (uuid) для запросов
4. Логирования запросов

**Middleware-компонент (промежуточное/связующее ПО)** - это **функция-обработчик**, которая находится в цепочке обработки запроса **между** началом (точкой входа в приложение) и конечной функцией-обработчиком, выполняющей всю бизнес-логику. Например, есть middleware-компоненты для аутентификации пользователя, обработки ошибок и обслуживания статических файлов (JS, CSS). 

По сути, middleware-функция очень похожа на обычный обработчик, она также принимает ответ типа `http.ResponseWriter` и запрос типа `*http.Request` (точнее принимает следующий обработчик в цепочке типа `http.Handler` и возвращает тоже `http.Handler`), **делает** что-то и **делегирует** запрос следующему обработчику - это может быть следующий middleware в цепочке или финальный обработчик запроса. Или эта функция может сделать какие-то манипуляции с ответом (например, добавить туда заголовки), прерывать эту цепочку и завершить запрос.

У пакета **context** есть [два основных назначения](https://www.youtube.com/watch?v=cbP1ShYndHg):
1. **Способ доставки уведомлений о том, что необходимо что-то завершить**
    * Например, есть HTTP-сервер, на который приходит запрос от клиента. И когда мы обрабатываем запрос (открывается соединение с БД, долгие запросы и т.д.), клиент отваливается. Чтобы мы могли высвободить ресурсы, чтобы мы знали, что в принципе дальше не нужно продолжать обработку запроса, существует пакет **context**, который позволяет распространять информацию о том, что нужно отменить какое-то действие всем горутинам, которые были где-то запущены. Для работы необходимо в аргументах передавать `context.Context` (контекст).
        * В частности, контекст можно использовать для **мягкой остановки приложения (graceful shutdown)**.
        *   <details>
            <summary>Жизненный цикл серверного приложения</summary>

            **Жизненный цикл серверного приложения** - **последовательность статусов (состояний)**, в которые переходит приложение от момента его запуска до непосредственной выгрузки его из оперативной памяти:
            1. **Инициализация**
                * У нас есть коннекты к базе данных, какие-то удаленные API или любые другие ресурсы, которыми необходимо будет пользоваться в процессе обработки запросов. На этом этапе необходимо **выполнить все настройки** этих ресурсов и по возможности **проверить их работоспособность**.
            2. **Старт**
                * Приложение запускает процесс чтения запросов из сети, выполняет их обработку и возвращает результат. Ничего такого - просто **рабочий процесс**.
            3. **Мягкое завершение (Graceful Shutdown)**
                * После получения от ОС команды о завершении работы наш сервис должен **завершить обработку текущих запросов** без потерь данных, и не стоит принимать новые запросы в этот момент.
            4. **Деинициализация**
                * Когда все процессы остановлены, нужно корректно **освободить все ресурсы**, в том числе все соединения с базами данных и другими удаленными серверами.

            Можно написать **контроллер Runtime**, который **управляет переходом** из одного состояния в другое. Данный модуль запускает функцию приложения, а в фоновом режиме контролирует работоспособность ресурсов и сигналы от ОС.
            
            **Методы контроллера Runtime:**
            * `Run` - запуск приложения.
            * `Halt` - перевод приложения в промежуточное состояние.
                * Если мы хотим настоящий **graceful shutdown**, тогда наш сервис не должен прерывать работу на середине, но должен переходить в такое состояние, при котором все новые запросы будут сразу же получать ответ `503` - сервис недоступен, а все текущие запросы будут корректно выполнены, и только после этого сервер выполнит остановку.
            * `Shutdown` - завершение (остановка) приложения.

            **Основные причины, по которым приложение должно завершить работу:**
            1. **Основной поток завершил работу**
                * Это может произойти с приложением, если его рабочий цикл четко определен и конечен. Выполнена работа - завершаем. Однако это не единственный пример.
            2. **Получено сообщение о завершении работы от ОС**
                * Нас в этом случае будет интересовать следующие сигналы: `SIGHUP`, `SIGINT`, `SIGTERM` и `SIGQUIT`.
            3. **Отсутствие возможности корректно продолжать работу**
                * Такая ситуация может наступить, если наше приложение потеряло какой-то ресурс: соединение с БД или любые другие критичные для выполнения запросов вещи.

            [Источник](https://habr.com/ru/companies/timeweb/articles/589167/)
            </details>
2. **Способ передачи значений**
    * Например, есть HTTP-сервер, на этапе middleware можно записывать `UserID`, который получаем из токена/сессии, в `context.Context`, чтобы в конечных обработчиках каждый раз не парсить токен/сессию, а **брать это значение из контекста**.

## Middleware-компонент для проверки аутентификации пользователя по JWT
Endpoint'ы для работы с todo-списками и отдельными задачами являются приватными. Необходимо закрыть публичный доступ к этим ресурсам и разрешить обращения только аутентифицированным пользователям.

Для этого создал middleware-компонент, который валидирует JWT-токен, пытается найти пользователя в БД по полю `UserID` из payload JWT. И в случае успеха, добавляет **структуру пользователя** в **контекст текущего запроса**, иначе возвращает статус-код `401` (`http.StatusUnauthorized`).

В директории `internal/controller/apiserver` в файле `apiserver.go` определил middleware-функцию `authenticateUser`, которая принимает следующий обработчик в цепочке типа `http.Handler` и возвращает тоже `http.Handler`.

Точнее возвращает:

```go
return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request){
    // ...
})
```

Перед `return` определил структуру `tokenClaims` с полем `UserID` типа `int` и анонимным полем типа `jwt.RegisteredClaims`.

В теле анонимной функции из поля `Header` запроса попытался прочитать заголовок `Authorization` с токеном. Помним, что клиент согласно **RFC 6750** посылает токен в формате `Authorization: Bearer токен`, поэтому распарсил содержимое заголовка с помощью функции `strings.Split` и сделал соответствующие проверки.

В случае ошибки, вызывал метод `error` со статус-кодом `http.StatusBadRequest` и `return`. При этом передавал кастомную ошибку `errIncorrectAuthHeader`, которую определил в том же файле `apiserver.go` с помощью функции `errors.New`. Далее записал строку с токеном в переменную `tokenString`.

Для **парсинга** и **валидации** токена использовал функцию `jwt.ParseWithClaims`, в которую передал `tokenString`, кастомный payload `tokenClaims` и callback-функцию с сигнатурой (`func(token *jwt.Token) (interface{}, error)`), в которой согласно [документации](https://pkg.go.dev/github.com/golang-jwt/jwt/v5) проверил поле `alg` в JWT-header (т.к. метод `HMAC`) и возвратил секретный ключ для проверки токена.

В случае ошибки вызывал метод `error` со статус-кодом `http.StatusUnauthorized` и `return`. В качестве ошибки можно передавать ту, которую возвращает функция `jwt.ParseWithClaims` (типа `ErrTokenSignatureInvalid`, `ErrTokenExpired`, `ErrTokenInvalidClaims` и т.д.), но я передавал абстрактную `errNotAuthenticated`, которую определил в файле `apiserver.go` с помощью функции `errors.New`.

Записал поля payload токена в переменную `claims`. Для преобразования типа интерфейса `jwt.Claims` в `*tokenClaims` использовал запись `value.typeName`.

Далее попытался найти пользователя в БД по `UserID` (вызвал `usecase` `UsersFindByID`). В случае ошибки вызывал метод `error` со статус-кодом `http.StatusUnauthorized` и `return`.

Если все корректно, вызывал **следующий обработчик** `next` с помощью метода `ServeHTTP`.

Чтобы **добавить структуру пользователя в контекст текущего запроса**, использовал метод `WithContext`, который заменяет текущий контекст на новый.

Для создания нового контекста использовал функцию `context.WithValue`, в которую передал **родительский контекст** (в частности, контекст текущего запроса возвращает метод `Context`), **ключ**, в котором хранится структура пользователя, и **структуру пользователя**.

Для ключей контекста в файле `apiserver.go` определил **отдельный** тип данных `ctxKey` типа `uint8` (чем больше значение, тем больше ключей), поскольку использовать какие-то стандартные типы данных (например, строки) не является хорошей практикой. И создал константу `ctxKeyUser` этого типа, которая является ключом пользователя в этом контексте.

В заключение добавил в файл `apiserver_internal_test.go` тест `TestServer_AuthenticateUser`.

<details>
    <summary> Замечания по реализации модульного теста middleware TestServer_AuthenticateUser</summary>

Срез анонимных структур `testCases` содержит поле названия sub-теста (`name`) и дополнительные поля:
* `tokenString` - функция, которая возвращает подписанный токен.
* `expectedCode` - `int`.

Middleware-компонент принимает `http.Handler`, поэтому создал **фейковый обработчик**, который записывает в ответ статус-код `http.StatusOK`:

```go
handler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
})
```

В sub-тестах рассмотрел 4 случая:
1. Пользователь аутентифицирован
2. Неправильный формат заголовка
3. Пользователь неаутентифицирован
4. Срок действия токена истек

Чтобы установить заголовок `Authorization` использовал метод `Set` поля `Header` структуры запроса `req`.
</details>

Для тестирования middleware для проверки аутентификации пользователя по JWT токену создал приватный endpoint для просмотра профиля пользователя.

Итак, в файле `apiserver.go` определил метод `handleUserProfile`, который возвращает статус-код `http.StatusOK` и **структуру пользователя из контекста запроса** (связка метода `Context` и `Value` с ключом `ctxKeyUser`).

Также в методе `configureRouter` с помощью метода `Handle` у поля `s.router` зарегистрировал middleware `authenticateUser` с endpointo'ом `handleUserProfile` (`s.authenticateUser(s.handleUserProfile())`) на обработку `GET` запросов на маршрут `/profile`.

В заключение добавил в файл `apiserver_internal_test.go` тест `TestServer_HandleUserProfile`, в котором использовал ту же конструкцию, что и в middleware обработчике, для записи структуры пользователя в контекст запроса - `req.WithContext(context.WithValue(req.Context(), ctxKeyUser, u))`, а для вызова обработчика - `s.handleUserProfile().ServeHTTP(rec, req)`. Проверил, что статус-код `http.StatusOK` и что тело ответа `rec` не пустое, с помощью функций `assert.Equal` и `assert.NotNil`, соответственно.

После сборки проекта отправил несколько тестовых запросов с помощью утилиты `curl`:

Невалидный:

```bash
curl --location --request GET http://localhost:8080/profile \
--header 'Authorization: Bearer ' -v
```

Кроме того, отправлял запросы **после истечения срока действия токена** и **с измененным JWT payload**.

Валидный:

```bash
curl --location --request GET http://localhost:8080/profile \
--header 'Authorization: Bearer токен' -v
```

## Middleware-компонент для CORS
Замечу, что на данном этапе API сервер не дружит с браузерами. Например, есть **API сервер**, который запущен на `8080` порту и **фронтенд-приложение**, которое использует веб-сервер, **запущенный на другом порту** (например, `3000`). Тогда, обращение из браузера на домен с другим портом - это **Cross-Origin HTTP-запрос**, для выполнения которого требуются специальные **CORS-заголовки** (`Access-Control-Allow-Origin`, `Access-Control-Allow-Methods`).

<details>
    <summary> Подробнее про CORS</summary>

**CORS (Cross Origin Resource Sharing)** - совместное использование ресурсов разных источников.
* Это стандарт, позволяющий предоставить доступ к объектам сторонних интернет ресурсов.
    * **Сторонним** считается любой интернет ресурс, который отличен от запрашиваемого:
        * Протоколом
        * Доменом
        * Портом
* Это механизм, использующий дополнительные HTTP-заголовки, чтобы дать возможность агенту-пользователя получать разрешения на доступ к выбранным ресурсам сервера на источнике (домене), отличном от того, что сайт использует в данный момент. Говорят, что агент пользователя делает запрос с другого источника (**cross-origin HTTP request**), если источник текущего документа отличается от запрашиваемого ресурса протоколом, доменом или портом.

[Источник](https://developer.mozilla.org/ru/docs/Web/HTTP/CORS)
</details>

Чтобы отдавать правильные CORS-заголовки, использовал middleware-компонент из библиотеки `gorilla/handlers`:

```bash
go get github.com/gorilla/handlers
```

Итак, в директории `internal/controller/apiserver` в файле `apiserver.go` в методе `configureRouter` с помощью метода `Use` и функции `handlers.CORS` добавил CORS-middleware в корневой роутер (поле `s.route`), так как он должен применяться ко всем запросам. В качестве аргументов в функция CORS принимает различные CORS настройки (например, доступные источники запросов, доступные методы). В данном случае передал фукнцию `handlers.AllowedOrigins`, с аргументом `[]string{"*"}`. Знак **wildcard** (`*`) означает, что разрешены запросы с **любых** источников (доменов).

После сборки проекта отправил тестовый запрос с помощью утилиты `curl`:

```bash
curl --location --request POST http://localhost:8080/tokens \
--header 'Origin: google.com' \
--data-raw '{
    "email":"user@example.org",
    "password":"password"
}' -v
```

В запросе передал заголовок `Origin` для имитации работы браузера. В этом заголовке браузер указывает хост, с которого пришел запрос.

## Middleware-компонент для RequestID
Чтобы идентифицировать, какие действия были вызваны каким запросом, реализовал middleware-компонент, который проставляет для каждого входящего запроса уникальный идентификатор `RequestID`, который будет:
1. передаваться в заголовке `X-Request-ID` ответа
2. использоваться внутри системы при логировании

В качестве идентификатора `RequestID` использовал **UUID**.

<details>
    <summary>Подробнее про UUID</summary>

**UUID (Universal Unique IDentifier)** - 128-битное число, которое в разработке ПО используется в качестве уникального идентификаиора элемента.

Его классическое текстовое представление является серией из 32 шестнадцатеричных символов, разделённых дефисами на пять групп по схеме `8-4-4-4-12`. Например: `9cd5f997-9ec5-44d5-92f4-e3d31c22c65e`.

[Источник](https://habr.com/ru/companies/vk/articles/522094/)
</details>

Для генерации UUID в go использовал библиотеку **google/uuid**:

```bash
go get github.com/google/uuid
```

В директории `internal/controller/apiserver` в файле `apiserver.go` определил middleware-функцию `setRequestID` с такой же сигнатурой как и `authenticateUser`.

С помощью функции `uuid.New` сгенерировал новый `id`, который конвертировал в строку методом `String`. Далее добавил `id` в заголовок ответа `X-Request-ID` (с помощью методов `Header` и `Set`) и вызвал следующий обработчик `next` с помощью метода `ServeHTTP`.

Аналогично передаче структуры пользователя использовал метод `WithContext`, чтобы **добавить UUID запроса в контекст**. Для ключа в функции `context.WithValue` создал еще одну константу `ctxKeyRequestID` типа `ctxKey`.

В заключении добавил в файл `apiserver_internal_test.go` тест `TestServer_SetRequestID`, в котором с помощью функций `assert.Equal` и `assert.NotEmpty` проверил, что статус-код `http.StatusOK` и заголовок ответа `X-Request-ID` не пустой.

Также в методе `configureRouter` с помощью метода `Use` добавил middleware `setRequestID` к корневому роутеру в самое начало цепочки, чтобы у всех следующих middleware-компонентов был доступ к `RequestID`.

После сборки проекта отправил тестовый запрос с помощью утилиты `curl`:

```bash
curl --location --request POST http://localhost:8080/tokens \
--data-raw '{
    "email":"user@example.org",
    "password":"password"
}' -v
```

## Middleware-компонент для логирования
Чтобы API сервер не работал, как черный ящик (black box), добавил **вывод логов** в консоль.

Для логирования использовал библиотеку **sirupsen/logrus**:

```bash
go get github.com/sirupsen/logrus
```

Замечу, что на данный момент есть более производительные библиотеки, например от [uber](https://github.com/uber-go/zap).

В **sirupsen/logrus** есть **7 уровней логирования**: `Trace`, `Debug`, `Info`, `Warning`, `Error`, `Fatal` and `Panic`, которые подробно описаны в [документации](https://pkg.go.dev/github.com/sirupsen/logrus).

Чтобы конфигурировать уровень логирования из `apiserver.toml` файла, добавил новое поле `LogLevel` в конфиг сервера, а в конструкторе `NewConfig` установил значение по умолчанию `debug`.
 
Далее в директории `internal/controller/apiserver` в файле `apiserver.go` добавил в структуру сервера приватное поле `logger` типа `*logrus.Logger`. В конструкторе `NewServer` создал новый логер с помощью функции `logrus.New`.

А также определил метод `configureLogger`, который возвращает ошибку, так как теоретически можно передать неправильную строку. С помощью функции `logrus.ParseLevel` **парсим** уровень логирования из поля `s.config.LogLevel`. Если ошибок нет, **устанавливаем** уровень логирования с помощью метода `SetLevel`.

В методе `StartServer` **вызвал** метод `configureLogger` и с помощью метода `Info` **вывел сообщение** уровня `Info` о запуске API сервера. Замечу, что если поднять `LogLevel` до уровня `Error`, то логер **пропустит** сообщение уровня `Info` о запуске API сервера, так как все сообщения ниже установленного уровня игнорируются.

В директории `internal/controller/apiserver` в файле `apiserver.go` определил middleware-функцию `logRequest`, который логирует каждый входящий запрос и имеет такую же сигнатуру как `setRequestID`. 

Внутри `logRequest` с помощью метода `WithFields` создал переменную `logger` типа `*logrus.Entry`, которая является **локальным логером** с полями, характерными для каждого конкретного запроса. А именно с полями `remote_addr` (IP-адрес клиента) и `request_id` (UUID запроса). Итак, в метод `WithFields` передал `map`'у `logrus.Fields`, IP-адрес клиента получил из поля `RemoteAddr` запроса, а UUID запроса из контекста запроса (связка метода `Context` и `Value` с ключом `ctxKeyRequestID`).

Далее с помощью метода `Infof` вывел сообщение уровня `Info` о начале обработки запроса (поля `r.Method`, `r.RequestURI`). Затем создал переменную `start`, в которую записал **время начала** обработки запроса с помощью функции `time.Now`. Это нужно, чтобы после отработки всех следующих обработчиков, можно было записать в логер сколько времени это заняло (метод `Sub`).

Помимо времени обработки запроса, вывел статус-код, с которым завершилась обработка запроса. Поскольку в метод `ServeHTTP` передается интерфейс `http.ResponseWriter`, у которого нет поля статус-кода, невозможно получить информацию о статус-коде, записанную в другом обработчике. 

Соответственно, в директории `internal/controller/apiserver` создал файл `responsewriter.go`, в котором определил структуру `responseWriter` с полем статус-кода `code` типа `int` и анонимным полем типа `http.ResponseWriter`, чтобы не надо было реализовывать все методы интерфейса `http.ResponseWriter` (они и так будут доступны внутри структуры).

Поскольку у интерфейса `http.ResponseWriter` статус-код записывается методом `WriteHeader`, переопределил его. В частности, записал значение `statusCode` в поле `w.code`, а затем вызвал у `w.ResponseWriter` метод `WriteHeader`.

Таким образом, новый `responseWriter` сохраняет обычную функциональность, потому что выполнение метода делегируется `w.ResponseWriter`, но при этом статус-код сохраняется в переменную.

Итак, в `logRequest` создал переменную `rw` типа `responseWriter`, в которую передал обычный `w` и `http.StatusOK`, а также переменную `level` типа `logrus.Level`, значение которой зависит от значения статус-кода. 

Для серверных ошибок (`rw.code >= 500`) уровень логирования `logrus.ErrorLevel`, для клиентских ошибок (`rw.code >= 400`) - `logrus.WarnLevel`, для всех остальных - `logrus.InfoLevel`.

Затем создал сообщение о результатах и времени выполнения запроса с помощью метода `Logf`, в который передал уровень логирования `level`, строку сообщения, статус-код `rw.code`, его текстовое представление (функция `http.StatusText`) и время.

Также в методе `configureRouter` с помощью метода `Use` добавил middleware `logRequest` сразу после `setRequestID`.

После сборки проекта отправил тестовый запрос с помощью утилиты `curl`:

```bash
curl --location --request POST http://localhost:8080/tokens \
--data-raw '{
    "email":"user@example.org",
    "password":"password"
}' -v
```

Замечу, что если поднять `LogLevel` до уровня `Error`, то логер **пропустит** сообщения уровней ниже (в частности, `Info` и `Warning`).

## Контейнеризация приложения. Dockerfile
Чтобы была возможность поднять проект командой `docker-compose up`, провел **контейнеризацию** проекта.

<details>
<summary>Терминология: контейнер, Docker и Docker Compose </summary>

* **Контейнер (Container)** - это изолированный процесс, ограниченный выделенным объемом ресурсов (ЦПУ, ОЗУ, диска и др.). В терминах Docker’а контейнер - это экземпляр образа (image). Контейнер объединяет двоичный код приложения, файлы конфигурации, библиотеки, зависимости и среду выполнения.
* **Docker** - платформа для управления **отдельными контейнерами**.
* **Docker Compose** - технология для одновременного управления **несколькими контейнерами**, входящими в состав приложения.
</details>

В данном проекте **два контейнера** (сервиса):
1. REST API сервер
2. PostgreSQL база данных

**Алгоритм создания контейнера следующий:**
1. Пишем `Dockerfile`
2. Создаем образ из `Dockerfile`
3. Создаем контейнер из образа

> Dockerfile -> Image -> Container

Итак, необходимо написать `Dockerfile` для серверного приложения, а для БД достаточно воспользоваться **базовым образом**.

<details>
<summary>Замечания по контейнеризации БД в зависимости от организации миграций</summary>

Контейнеризацию БД можно провести **по-разному** в зависимости от организации **миграций**:
* Можно воспользоваться библиотекой **golang-migrate/migrate** (или даже позаимствовать [готовый код](https://github.com/evrone/go-clean-template/blob/master/internal/app/migrate.go) для `init` функции из широко известного репозитория [evrone/go-clean-template](https://github.com/evrone/go-clean-template)), которая позволит **серверному приложению прогнать миграции** и создать все необходимые таблицы в контейнере БД. В этом случае, **не требуется** создавать `Dockerfile` для БД, можно воспользоваться **готовым образом** уже на этапе написания `docker-compose.yaml`.
* Можно создать отдельный `Dockerfile` для БД, скопировать `.sql` скрипты для создания таблиц в директорию `/docker-entrypoint-initdb.d/` образа. Тогда никакой **дополнительный код в серверном приложении не нужен**, при первом запуске контейнера БД `.sql` скрипты выполнятся и произойдет инициализация БД.
</details>

В официальной документации **Docker** есть [описание всех инструкций](https://docs.docker.com/engine/reference/builder/), [рекомендации по написанию Dockerfile](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) и [пример контейнеризации Go приложения](https://docs.docker.com/language/golang/build-images/), поэтому далее я лишь прокомментирую `Dockerfile` для REST API сервера.

Замечу, что за **основу** можно взять [Dockefile](https://github.com/evrone/go-clean-template/blob/master/Dockerfile) из уже упомянутого в замечании репозитория [evrone/go-clean-template](https://github.com/evrone/go-clean-template).

```Dockerfile
# Step 1: Modules caching
FROM golang:alpine as modules
COPY go.mod go.sum /modules/
WORKDIR /modules
RUN go mod download

# Step 2: Builder
FROM golang:alpine as builder
COPY --from=modules /go/pkg /go/pkg
COPY . /app
WORKDIR /app
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 \
    go build -tags migrate -o /bin/app ./cmd/app

# Step 3: Final
FROM scratch
COPY --from=builder /app/configs /configs
COPY --from=builder /app/migrations /migrations
COPY --from=builder /bin/app /app
CMD ["/app"]
```

Перед тем как описать каждую инструкцию, напомню, что для создания более **компактных Docker образов** используют **многоэтапную сборку (multi-stage builds)**. MultiStage сборка - создание временного и финального образа на базе легковесного.

Для **инициализации нового этапа сборки** используется инструкция `FROM`, с помощью инструкции `COPY` с флагом `--from` можно **выборочно** копировать файлы с одного этапа на другой, оставляя все не нужное, что позволяет **уменьшить размер финального образа**.

В данном случае `Dockerfile` состоит из трех отдельных этапов:
1. Загрузка используемых зависимостей в **кэш** (каталог `/go/pkg`) с помощью команды `go mod download`.
2. **Компиляция** проекта с помощью команды `go build`.
3. Копирование **исполняемого файла** со второго этапа.

Замечу, что в качестве базового образа на **первом** и **втором** слое используется образ Go с тегом `alpine` (легкий дистрибутив **Linux**), а на **третьем** - `docker scratch` - это пустой Docker образ, размер которого - `0 Mb`.

**Сводка по использованным инструкциям:**
* `FROM <image:tag> as <name>` - инициализирует новый этап сборки (новый слой) и устанавливает базовый образ для последующих инструкций.
    * Опционально принимает флаг ОС `--platform` (по-умолчанию используется ОС, с которой приходит запрос на сборку). 
* `COPY --from=<name> <src> <dest>` - копирует новые файлы из `src` и добавляет их в файловую систему контейнера по пути `dest`.
    * Опционально принимает флаг `--from`, который позволяет копировать файлы из другого слоя `name`.
    * Существует инструкция `ADD`, с более расширенным функционалом, чем `COPY`, но рекомендуют использовать `COPY`.
* `WORKDIR <path>` - устанавливает рабочую директорию для любых инструкций `RUN`, `CMD`, `ENTRYPOINT`, `COPY`, `ADD`, которые следуют за ней в `Dockerfile`.
* `RUN <command>` - выполняет команды в новом слое поверх текущего образа и фиксирует результаты.
* `CMD ["executable", "param1", "param2"]` - предоставляет значение по-умолчанию для запуска контейнера.
    * CMD может быть только одна в `Dockerfile`.
    * Не путайте `RUN` с `CMD`: `RUN` фактически запускает команду и фиксирует результат, `CMD` ничего не выполняет во время сборки, только указывает на предполагаемую команду.

Пояснение флагов в команде `go build`:
* `CGO_ENABLED` - мы отключаем `CGO`, таким образом мы получаем скомпилированное Go-приложение вместе с статически связанными **C-библиотеками**, поэтому наш бинарник будет работать без каких-либо внешних зависимостей.
* `GOOS=linux` - мы указываем Linux в качестве ОС.

Итак, в директории `internal/app` создал файл `migrate.go`, в котором определил вторую функцию `init` и скопировал в нее [готовый код](https://github.com/evrone/go-clean-template/blob/master/internal/app/migrate.go).

```bash
go get github.com/golang-migrate/migrate/v4
```

Команда `go build` с флагом `-tags` позволяет добавлять файлы в сборку. Чтобы **VSCode** не ругался на **тэг сборки (build tag)**, добавил тэг `migrate` по пути `Settings -> User -> Go -> Build Tags`.

Создал образ `todo-app` командой:

```bash
docker build . -t todo-app
```

Убедился, что образ создался командой:

```bash
docker images
```

Создал одноименный контейнер:

```bash
docker run -p 8080:8080 --name todo-app todo-app
```

## Развертывание приложения. Docker Compose
**Docker Compose** - инструмент, позволяющий запускать среды приложений с **несколькими контейнерами** на основе определений, задаваемых в `.yaml` файле.

## Полезные ссылки
* [REST API на Golang](https://www.youtube.com/playlist?list=PLehOyJfJkFkJ5m37b4oWh783yzVlHdnUH)